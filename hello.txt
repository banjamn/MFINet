
Reviewer #2: 

(1)Suggest adding a comparison of computational efficiency between different algorithms in the experiment.
(2)There are a few spelling errors in the text, it is recommended to check again. For example in Page 2, "After that, inspired by prior effort [22], which emphasizes the importance of color and texture features. We incorporate skip connections of RGB features in TMFF module, which emphasizes the dominant role of RGB features in the fusion process." should be "After that, inspired by prior effort [22] which emphasizes the importance of color and texture features, we incorporate skip connections of RGB features in TMFF module to emphasize the dominant role of RGB features in the fusion process."


Reviewer #3: 

1. The resolution of the figures is low, especially for Figure. 8, 9, and 10. Please improve the quality of the figures.

2. In NLFE module, what is the differences between CA1 and CA2? What is the purpose of using CA1 and CA2 in series?

3. In TMFF module, why re-introduce RGB features at the end of this module? What is the rationale for the unequal treatment of features from different modalities?

4. It is recommended to include a description of future research directions in the conclusion section.

5. In Eq. 2 and Eq. 6, for better clarity, it is advisable to use brackets of varying sizes, such as '\big(', when handling multiple nested brackets.

6. In Eq. 7, the authors do not specify which features are subject to deep supervision. It is recommended to provide a detailed explanation here.

7. There are some format issues, such as:
(1) In Eq. 4, there is an alignment issue.
(2) In Eq. 8, there is a format issue.



Reviewer #4: 

1. Would you consider making the source code publicly available to foster future research in this line?

2. Some recent state-of-the-art multi-modal fusion methods like CMNeXt and GeminiFusion could be discussed and compared.

3. Please reference the compared methods directly in the experiment tables.

4. In addition to the comparison of the overall models, the proposed feature integration and fusion modules should be compared against existing feature fusion methods like cross-attention-based and various fusion methods. This would better verify the superiority of the proposed method.

5. Please consider adding more ablation studies by using different modalities like thermal-depth and visible-depth modalities. This would help providing more insights. In addition to the VDT-2048 dataset, would it be possible to also verify your proposed solution on another public dataset? This should be discussed.

6. Some limitations of the presented work could be discussed and some future work directions could be pointed out.

7. The captions of the some figures like Fig. 2 could be enriched to help the readers better understand the presented work.

8. Computational efficiency is critical for real-world applications. Please consider presenting more computational complexity results like FLOPs/MACs, the number of parameters, and running time for analysis.

Reviewer #5: 
1. The purpose, motivation, and hypotheses of the study should be clarified. Additionally, clarifying the main challenges faced by the discussed topic would be beneficial.

2. What is the basis for the design of the network architecture? Although the authors introduce each structural component, there is no analysis of the design rationale behind the network structure. Why use the encoder-decoder architecture? Why is this network architecture feasible? How do these structural components affect the results? Why use tri-modal data? Overall, the introduction of the proposed method is poorly done and lacks profound theoretical insight.

3. An analysis of the advantages and limitations of the proposed method is missing. Although the authors analyze failure cases, discussing its advantages and limitations is necessary.

4. Computational details and sample details should be provided in the performance evaluation.

5. To validate the superiority of the proposed algorithm, the authors compared several methods. Why compare these methods? Are these methods representative? Have the parameters of these algorithms been properly set? Is the performance comparison fair?

6. Based on the quantitative comparison results provided by the authors, the performance differences between the proposed method and the compared algorithms appear to be insignificant. This should be analyzed in depth. Can similar results be obtained with different datasets and scenarios?

7. Please provide statistical significance test results to assess whether the performance differences between the compared algorithms are significant.
8. What factors will affect the results in practical applications? Please provide necessary discussion.

9.  The conclusion is brief. Please consider rewriting it.

10. The writing, organization, and readability of the manuscript can be further improved.
